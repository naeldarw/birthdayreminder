{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75YQ1EIsYzwk"
      },
      "source": [
        "# Intro to Python: Exercise 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5vkveeAYzwl"
      },
      "source": [
        "## Linear regression with one variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1xe0jHjYzwl"
      },
      "source": [
        "In the first part of the exercise, we're tasked with implementing linear regression with one variable to predict profits for a food truck. Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet. The chain already has trucks in various cities and you have data for profits and populations from the cities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKkrQMMoYzwl"
      },
      "source": [
        "Let's start by importing some libraries and examining the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqe4ulo9Yzwl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPAwVLCzYzwm"
      },
      "source": [
        "Read the data from the CSV file using Panda library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niZWRieSYzwm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/vita-epfl/DLAV-2025.git\n",
        "path = os.getcwd() + '/DLAV-2025/homeworks/hw1/data/ex1data1.txt'\n",
        "data = pd.read_csv(path, header=None, names=['Population', 'Profit'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSjar-QEYzwm"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiK2KbTOYzwm"
      },
      "source": [
        "Let's plot it to get a better idea of what the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN-hYBvzYzwm"
      },
      "outputs": [],
      "source": [
        "data.plot(kind='scatter', x='Population', y='Profit', figsize=(12,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w7kVKIgYzwm"
      },
      "source": [
        "Now let's implement linear regression using gradient descent to minimize the cost function.  The equations implemented in the following code samples are detailed in \"ex1.pdf\" in the \"exercises\" folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aTRXPtDYzwn"
      },
      "source": [
        "First we'll create a function to compute the cost of a given solution (characterized by the parameters theta). The cost function is the Mean Sqaured error in matrix form:\n",
        "\n",
        "$$ MSE(\\theta) = \\frac{1}{N}\\sum_n^N [ y_n-x_n^T*\\theta]^2 $$\n",
        "\n",
        "where $\\theta$ and $x_n$ are vectors\n",
        "\n",
        "__Hint__: Use the matrix form of the cost function and make use of numpy operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26EIyq1EYzwn"
      },
      "outputs": [],
      "source": [
        "def computeCost(x, y, theta):\n",
        "    # Compute the cost function\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVpagN7AYzwn"
      },
      "source": [
        "Let's add a column of ones to the training set so we can use a vectorized solution to computing the cost and gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u18-E8cBYzwn"
      },
      "outputs": [],
      "source": [
        "data.insert(0, 'Ones', 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2I3NlK-Yzwn"
      },
      "source": [
        "Now let's do some variable initialization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjmZ1P6TYzwn"
      },
      "outputs": [],
      "source": [
        "# set X (training data) and y (target variable)\n",
        "cols = data.shape[1]\n",
        "X = data.iloc[:,0:cols-1]\n",
        "y = data.iloc[:,cols-1:cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfJ5E5PDYzwn"
      },
      "source": [
        "Let's take a look to make sure X (training set) and y (target variable) look correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwwhtjQKYzwn"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq4mYvfTYzwn"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l97ElId8Yzwo"
      },
      "source": [
        "Convert X and Y to numpy array for better manipulation. Initiliaze Theta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyRupf6PYzwo"
      },
      "outputs": [],
      "source": [
        "X = np.array(X.values)\n",
        "y = np.array(y.values).flatten()\n",
        "theta = np.array([0,0])\n",
        "theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1SvFSopYzwo"
      },
      "source": [
        "Let's take a quick look at the shape of our matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty3cxVtMYzwo"
      },
      "outputs": [],
      "source": [
        "X.shape, theta.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHJBVkQQYzwo"
      },
      "source": [
        "Now let's compute the cost for our initial solution (0 values for theta)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA46VJIKYzwo"
      },
      "outputs": [],
      "source": [
        "computeCost(X, y, theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AMO12hLYzwo"
      },
      "source": [
        "So far so good.  Now we need to define a function to perform gradient descent on the parameters theta using the update rules. Write first a function that computes the gradient of a matrix and then use it in the gradientDescent function.\n",
        "\n",
        "The gradient descent formula is:\n",
        "\n",
        "$$\\theta^{t+1} = \\theta^{t} - \\alpha*\\nabla MSE(\\theta^{t})$$\n",
        "\n",
        "where $\\nabla MSE(\\theta^{t})$ is the gradient of the cost function at $\\theta^{t}$\n",
        "\n",
        "__Hint__: Use the matrix form of the gradient and make use of numpy operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzhZukvzYzwo"
      },
      "outputs": [],
      "source": [
        "def compute_gradient(y, tx, w):\n",
        "    \"\"\"Compute the gradient.\"\"\"\n",
        "    # ***************************************************\n",
        "    # INSERT YOUR CODE HERE\n",
        "    # TODO: compute gradient and loss\n",
        "    # ***************************************************\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkBFteWgYzwo"
      },
      "outputs": [],
      "source": [
        "def gradientDescent(X, y, theta, alpha,max_iters):\n",
        "    \"\"\"Gradient descent algorithm.\"\"\"\n",
        "    # Define parameters to store w and loss\n",
        "    ws = [theta]\n",
        "    cost = np.zeros(max_iters)\n",
        "    for n_iter in range(max_iters):\n",
        "        # ***************************************************\n",
        "        # INSERT YOUR CODE HERE\n",
        "        # TODO: compute gradient and loss\n",
        "        # ***************************************************\n",
        "        raise NotImplementedError\n",
        "        # ***************************************************\n",
        "        # INSERT YOUR CODE HERE\n",
        "        # TODO: update theta by gradient\n",
        "        # ***************************************************\n",
        "        raise NotImplementedError\n",
        "        # store w and loss\n",
        "        ws.append(theta)\n",
        "        cost[n_iter] = loss\n",
        "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
        "              bi=n_iter, ti=max_iters - 1, l=loss, w0=theta[0], w1=theta[1]))\n",
        "\n",
        "    return theta, cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHDbUqowYzwo"
      },
      "source": [
        "Initialize some additional variables - the learning rate alpha, and the number of iterations to perform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBkl1oRaYzwp"
      },
      "outputs": [],
      "source": [
        "alpha = 0.01\n",
        "iters = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDOsa3EeYzwp"
      },
      "source": [
        "Now let's run the gradient descent algorithm to fit our parameters theta to the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HINLoJ1RYzwp"
      },
      "outputs": [],
      "source": [
        "g, cost = gradientDescent(X, y, theta, alpha, iters)\n",
        "g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM-qiZlyYzwp"
      },
      "source": [
        "Finally we can compute the cost (error) of the trained model using our fitted parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtsBlLq3Yzwp"
      },
      "outputs": [],
      "source": [
        "computeCost(X, y, g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOo9IuNPYzwp"
      },
      "source": [
        "Now let's plot the linear model along with the data to visually see how well it fits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeY0NZfGYzwp"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(data.Population.min(), data.Population.max(), 100)\n",
        "f = g[0] + (g[1] * x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax.plot(x, f, 'r', label='Prediction')\n",
        "ax.scatter(data.Population, data.Profit, label='Traning Data')\n",
        "ax.legend(loc=2)\n",
        "ax.set_xlabel('Population')\n",
        "ax.set_ylabel('Profit')\n",
        "ax.set_title('Predicted Profit vs. Population Size')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ACa1zEFYzwp"
      },
      "source": [
        "Looks pretty good!  Since the gradient decent function also outputs a vector with the cost at each training iteration, we can plot that as well.  Notice that the cost always decreases - this is an example of a convex optimization problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDyjpof_Yzwq"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax.plot(np.arange(iters), cost, 'r')\n",
        "ax.set_xlabel('Iterations')\n",
        "ax.set_ylabel('Cost')\n",
        "ax.set_title('Error vs. Training Epoch')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}